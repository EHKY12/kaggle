{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007231,
     "end_time": "2024-09-22T19:11:39.945307",
     "exception": false,
     "start_time": "2024-09-22T19:11:39.938076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style=\"background-color: #1B1212; font-size: 300%; text-align: center; border-radius: 40px 40px; color: #C9A9A6; font-weight: bold; font-family: 'Cinzel', serif; text-transform: uppercase; border: 4px solid #C9A9A6;\">imports</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T00:38:42.301238Z",
     "iopub.status.busy": "2024-11-29T00:38:42.300931Z",
     "iopub.status.idle": "2024-11-29T00:38:42.311174Z",
     "shell.execute_reply": "2024-11-29T00:38:42.310151Z",
     "shell.execute_reply.started": "2024-11-29T00:38:42.301214Z"
    },
    "papermill": {
     "duration": 4.499927,
     "end_time": "2024-09-22T19:11:45.449251",
     "exception": false,
     "start_time": "2024-09-22T19:11:40.949324",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 및 설정\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import polars as pl  # Pandas와 비슷하지만 대규모 데이터 처리에 더 나은 성능 제공\n",
    "import pandas as pd  # CSV 파일을 로드하고 처리하는 라이브러리\n",
    "import numpy as np  # 수학적 계산 및 행렬 연산 라이브러리\n",
    "\n",
    "# KFold 관련 라이브러리\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupKFold  # Stratified 및 Group 기반의 K-Fold 교차 검증\n",
    "from sklearn.metrics import mean_squared_error as mse  # RMSE 계산용 함수\n",
    "\n",
    "# 모델 관련 라이브러리\n",
    "import lightgbm as lgb  # LightGBM 라이브러리\n",
    "from lightgbm import LGBMRegressor, log_evaluation, early_stopping\n",
    "from catboost import CatBoostRegressor  # CatBoost 모델 라이브러리\n",
    "from xgboost import XGBRegressor  # XGBoost 모델 라이브러리\n",
    "\n",
    "import dill  # Python 객체 직렬화/역직렬화 (모델 저장 및 로드)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # 텍스트 데이터를 TF-IDF 특성으로 변환\n",
    "import re  # 정규 표현식 라이브러리\n",
    "import gc  # 가비지 컬렉션 (메모리 정리)\n",
    "import matplotlib.pyplot as plt  # 시각화 라이브러리\n",
    "import plotly.graph_objects as go  # Plotly 기반의 고급 그래프 생성\n",
    "import warnings  # 경고 메시지 무시 설정\n",
    "from sklearn.preprocessing import StandardScaler  # 데이터 표준화\n",
    "\n",
    "# PyTorch (딥러닝 프레임워크)\n",
    "import torch\n",
    "import torch.nn as nn  # Neural Network 모듈\n",
    "import torch.optim as optim  # Optimizer 모듈\n",
    "from torch.utils.data import Dataset, DataLoader  # Dataset 및 DataLoader 정의\n",
    "\n",
    "# 경고 메시지 무시\n",
    "warnings.filterwarnings('ignore')  # filterwarnings()를 통해 불필요한 경고 메시지 숨김\n",
    "\n",
    "import random  # 랜덤 관련 함수\n",
    "sys.path.append(\"/kaggle/input/um-game-playing-strength-of-mcts-variants\")  # MCTS 관련 모듈 경로 추가\n",
    "import kaggle_evaluation.mcts_inference_server  # MCTS 대회용 API\n",
    "\n",
    "# Pandas 옵션 설정 (모든 행과 열 출력)\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# 설정 클래스 정의\n",
    "class APP:\n",
    "    small_iterations = True  # 작은 데이터셋 반복 설정\n",
    "    short_dataset = True  # 간소화된 데이터셋 사용 여부\n",
    "    test_full_dataset = False  # 전체 테스트 데이터셋 사용 여부\n",
    "    local = os.environ.get(\"DOCKER_USING\", \"\") == \"LOCAL\"  # 로컬 실행 여부 확인\n",
    "    submit = os.environ.get('KAGGLE_IS_COMPETITION_RERUN', \"\") != \"\"  # 제출 여부 확인\n",
    "    path_root = Path('/kaggle/input')  # 데이터 경로\n",
    "    input_path = path_root / 'um-game-playing-strength-of-mcts-variants'\n",
    "    train_file = input_path / 'train.csv'  # 학습 데이터 경로\n",
    "    test_file = input_path / ('test_full.csv' if test_full_dataset else 'test.csv')  # 테스트 데이터 경로\n",
    "    sample_subm_file = input_path / ('sample_subm_full.csv' if test_full_dataset else 'sample_submission.csv')  # 샘플 제출 경로\n",
    "\n",
    "    # 대회 제출 환경에서는 간소화 설정 해제\n",
    "    if submit:\n",
    "        small_iterations = False\n",
    "        short_dataset = False\n",
    "        test_full_dataset = False\n",
    "\n",
    "# 랜덤 시드 설정 함수 (재현 가능성 확보)\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)  # NumPy 랜덤 시드 설정\n",
    "    random.seed(seed)  # Python 내장 랜덤 시드 설정\n",
    "    # 필요한 경우 Torch 및 기타 라이브러리 시드 설정 가능\n",
    "\n",
    "seed_everything(seed=2024)  # 고정된 랜덤 시드 값\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# **》》》Model1**\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T00:38:42.539754Z",
     "iopub.status.busy": "2024-11-29T00:38:42.539510Z",
     "iopub.status.idle": "2024-11-29T00:38:52.373344Z",
     "shell.execute_reply": "2024-11-29T00:38:52.372469Z",
     "shell.execute_reply.started": "2024-11-29T00:38:42.539731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class model_1:\n",
    "    train=pl.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\n",
    "    train=train.to_pandas()\n",
    "    print(f\"len(train):{len(train)}\")\n",
    "    test=pl.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "    test=test.to_pandas()\n",
    "    print(f\"len(test):{len(test)}\")\n",
    "    test.head()\n",
    "\n",
    "    class Preprocessor():\n",
    "        def __init__(self,seed=2024,target='utility_agent1',train=None,num_folds=10,CV_LB_path=\"/kaggle/input/mcts-eda-about-cv-and-lb/1018CV_LB.csv\"):\n",
    "            self.seed=seed\n",
    "            self.target=target\n",
    "            self.train=train\n",
    "            self.model_paths = []  # 학습 및 추론용 모델 경로\n",
    "            self.tfidf_paths = []  # 문자열의 TF-IDF 모델 경로\n",
    "            self.num_folds = num_folds\n",
    "            # CV와 LB 상태 확인용 데이터 (현재 비활성화)\n",
    "            # self.check = pd.read_csv(CV_LB_path)\n",
    "            \n",
    "            # 문자열 컬럼 전처리\n",
    "        def clean(self, df, col):\n",
    "            # 문자열의 결측값을 \"nan\"으로 대체\n",
    "            df[col] = df[col].fillna(\"nan\")\n",
    "            # 문자열을 소문자로 변환\n",
    "            df[col] = df[col].apply(lambda x: x.lower())\n",
    "            # 특정 특수문자들을 제거\n",
    "            ps = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "            for p in ps:\n",
    "                df[col] = df[col].apply(lambda x: x.replace(p, ' '))\n",
    "            return df\n",
    "        \n",
    "            # ARI (자동 읽기 가능성 지수): 텍스트의 가독성을 평가하는 척도\n",
    "        def ARI(self, txt):\n",
    "            characters = len(txt)  # 총 문자 수\n",
    "            words = len(re.split(r' |\\n|\\.|\\?|\\!|\\,', txt))  # 단어 수\n",
    "            sentence = len(re.split(r'\\.|\\?|\\!', txt))  # 문장 수\n",
    "            ari_score = 4.71 * (characters / words) + 0.5 * (words / sentence) - 21.43\n",
    "            return ari_score\n",
    "    \n",
    "        # McAlpine EFLAW 테스트: 가독성 점수를 계산\n",
    "        def McAlpine_EFLAW(self, txt):\n",
    "            words = len(re.split(r' |\\n|\\.|\\?|\\!|\\,', txt))  # 단어 수\n",
    "            sentences = len(re.split(r'\\.|\\?|\\!', txt))  # 문장 수\n",
    "            mcalpine_eflaw_score = (words + sentences * words) / sentences\n",
    "            return mcalpine_eflaw_score\n",
    "    \n",
    "        # CLRI (콜맨-리아우 가독성 지수): 텍스트 가독성을 평가\n",
    "        def CLRI(self, txt):\n",
    "            characters = len(txt)  # 총 문자 수\n",
    "            words = len(re.split(r' |\\n|\\.|\\?|\\!|\\,', txt))  # 단어 수\n",
    "            sentences = len(re.split(r'\\.|\\?|\\!', txt))  # 문장 수\n",
    "            L = 100 * characters / words  # 단어당 평균 문자 수\n",
    "            S = 100 * sentences / words  # 100단어당 문장 수\n",
    "            clri_score = 0.0588 * L - 0.296 * S - 15.8\n",
    "            return clri_score\n",
    "    \n",
    "        # 객체를 지정된 경로에 저장\n",
    "        def pickle_dump(self, obj, path):\n",
    "            with open(path, mode=\"wb\") as f:\n",
    "                dill.dump(obj, f, protocol=4)\n",
    "    \n",
    "        # 지정된 경로에서 객체를 로드\n",
    "        def pickle_load(self, path):\n",
    "            with open(path, mode=\"rb\") as f:\n",
    "                data = dill.load(f)\n",
    "            return data\n",
    "        \n",
    "        def reduce_mem_usage(self, df, float16_as32=True):\n",
    "            \"\"\"\n",
    "            데이터프레임의 각 열 데이터 타입을 변경하여 메모리 사용량을 줄입니다.\n",
    "        \n",
    "            Args:\n",
    "                df (pd.DataFrame): 입력 데이터프레임\n",
    "                float16_as32 (bool): True이면 float16 대신 float32로 변환\n",
    "        \n",
    "            Returns:\n",
    "                pd.DataFrame: 메모리 최적화된 데이터프레임\n",
    "            \"\"\"\n",
    "        # 초기 메모리 사용량 계산\n",
    "            start_mem = df.memory_usage().sum() / 1024**2\n",
    "            print(f'초기 메모리 사용량: {start_mem:.2f} MB')\n",
    "    \n",
    "            # 각 열을 순회하며 데이터 타입 최적화\n",
    "            for col in df.columns:\n",
    "                col_type = df[col].dtype\n",
    "        \n",
    "                # object나 category가 아닌 경우만 처리 (숫자형 데이터만 해당)\n",
    "                if col_type != object and str(col_type) != 'category':\n",
    "                    c_min, c_max = df[col].min(), df[col].max()  # 최소값과 최대값 계산\n",
    "        \n",
    "                    if str(col_type)[:3] == 'int':  # 정수형 처리\n",
    "                        # 값의 범위에 따라 적절한 정수형 데이터 타입으로 변환\n",
    "                        if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                            df[col] = df[col].astype(np.int8)\n",
    "                        elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                            df[col] = df[col].astype(np.int16)\n",
    "                        elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                            df[col] = df[col].astype(np.int32)\n",
    "                        elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                            df[col] = df[col].astype(np.int64)\n",
    "                    else:  # 실수형 처리\n",
    "                        # 값의 범위에 따라 적절한 실수형 데이터 타입으로 변환\n",
    "                        if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                            if float16_as32:  # float16 대신 float32 사용 여부에 따라\n",
    "                                df[col] = df[col].astype(np.float32)\n",
    "                            else:\n",
    "                                df[col] = df[col].astype(np.float16)\n",
    "                        elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                            df[col] = df[col].astype(np.float32)\n",
    "                        else:\n",
    "                            df[col] = df[col].astype(np.float64)\n",
    "    \n",
    "            # 최적화 후 메모리 사용량 계산\n",
    "            end_mem = df.memory_usage().sum() / 1024**2\n",
    "            print(f'최적화 후 메모리 사용량: {end_mem:.2f} MB')\n",
    "            print(f'감소율: {100 * (start_mem - end_mem) / start_mem:.1f}%')\n",
    "        \n",
    "            return df\n",
    "            \n",
    "        def FE(self,df,mode='train'):\n",
    "            print(f\"FE:{mode}\")\n",
    "\n",
    "            print(\"agent position feature\")\n",
    "            # 모든 에이전트 이름 리스트\n",
    "            total_agent=['MCTS-ProgressiveHistory-0.1-MAST-false', 'MCTS-ProgressiveHistory-0.1-MAST-true', 'MCTS-ProgressiveHistory-0.1-NST-false', 'MCTS-ProgressiveHistory-0.1-NST-true', 'MCTS-ProgressiveHistory-0.1-Random200-false', 'MCTS-ProgressiveHistory-0.1-Random200-true', 'MCTS-ProgressiveHistory-0.6-MAST-false', 'MCTS-ProgressiveHistory-0.6-MAST-true', 'MCTS-ProgressiveHistory-0.6-NST-false', 'MCTS-ProgressiveHistory-0.6-NST-true', 'MCTS-ProgressiveHistory-0.6-Random200-false', 'MCTS-ProgressiveHistory-0.6-Random200-true', 'MCTS-ProgressiveHistory-1.41421356237-MAST-false', 'MCTS-ProgressiveHistory-1.41421356237-MAST-true', 'MCTS-ProgressiveHistory-1.41421356237-NST-false', 'MCTS-ProgressiveHistory-1.41421356237-NST-true', 'MCTS-ProgressiveHistory-1.41421356237-Random200-false', 'MCTS-ProgressiveHistory-1.41421356237-Random200-true', 'MCTS-UCB1-0.1-MAST-false', 'MCTS-UCB1-0.1-MAST-true', 'MCTS-UCB1-0.1-NST-false', 'MCTS-UCB1-0.1-NST-true', 'MCTS-UCB1-0.1-Random200-false', 'MCTS-UCB1-0.1-Random200-true', 'MCTS-UCB1-0.6-MAST-false', 'MCTS-UCB1-0.6-MAST-true', 'MCTS-UCB1-0.6-NST-false', 'MCTS-UCB1-0.6-NST-true', 'MCTS-UCB1-0.6-Random200-false', 'MCTS-UCB1-0.6-Random200-true', 'MCTS-UCB1-1.41421356237-MAST-false', 'MCTS-UCB1-1.41421356237-MAST-true', 'MCTS-UCB1-1.41421356237-NST-false', 'MCTS-UCB1-1.41421356237-NST-true', 'MCTS-UCB1-1.41421356237-Random200-false', 'MCTS-UCB1-1.41421356237-Random200-true', 'MCTS-UCB1GRAVE-0.1-MAST-false', 'MCTS-UCB1GRAVE-0.1-MAST-true', 'MCTS-UCB1GRAVE-0.1-NST-false', 'MCTS-UCB1GRAVE-0.1-NST-true', 'MCTS-UCB1GRAVE-0.1-Random200-false', 'MCTS-UCB1GRAVE-0.1-Random200-true', 'MCTS-UCB1GRAVE-0.6-MAST-false', 'MCTS-UCB1GRAVE-0.6-MAST-true', 'MCTS-UCB1GRAVE-0.6-NST-false', 'MCTS-UCB1GRAVE-0.6-NST-true', 'MCTS-UCB1GRAVE-0.6-Random200-false', 'MCTS-UCB1GRAVE-0.6-Random200-true', 'MCTS-UCB1GRAVE-1.41421356237-MAST-false', 'MCTS-UCB1GRAVE-1.41421356237-MAST-true', 'MCTS-UCB1GRAVE-1.41421356237-NST-false', 'MCTS-UCB1GRAVE-1.41421356237-NST-true', 'MCTS-UCB1GRAVE-1.41421356237-Random200-false', 'MCTS-UCB1GRAVE-1.41421356237-Random200-true', 'MCTS-UCB1Tuned-0.1-MAST-false', 'MCTS-UCB1Tuned-0.1-MAST-true', 'MCTS-UCB1Tuned-0.1-NST-false', 'MCTS-UCB1Tuned-0.1-NST-true', 'MCTS-UCB1Tuned-0.1-Random200-false', 'MCTS-UCB1Tuned-0.1-Random200-true', 'MCTS-UCB1Tuned-0.6-MAST-false', 'MCTS-UCB1Tuned-0.6-MAST-true', 'MCTS-UCB1Tuned-0.6-NST-false', 'MCTS-UCB1Tuned-0.6-NST-true', 'MCTS-UCB1Tuned-0.6-Random200-false', 'MCTS-UCB1Tuned-0.6-Random200-true', 'MCTS-UCB1Tuned-1.41421356237-MAST-false', 'MCTS-UCB1Tuned-1.41421356237-MAST-true', 'MCTS-UCB1Tuned-1.41421356237-NST-false', 'MCTS-UCB1Tuned-1.41421356237-NST-true', 'MCTS-UCB1Tuned-1.41421356237-Random200-false', 'MCTS-UCB1Tuned-1.41421356237-Random200-true']\n",
    "            # 'agent1'과 'agent2' 열의 값을 배열로 가져오기\n",
    "            agent1,agent2=df['agent1'].values,df['agent2'].values\n",
    "            for i in range(len(total_agent)): # 각 에이전트에 대해 반복\n",
    "                value=np.zeros(len(df))\n",
    "                for j in range(len(df)):# agent1이 현재 에이전트인 경우 값을 +1 증가\n",
    "                    if agent1[j]==total_agent[i]:# agent2가 현재 에이전트인 경우 값을 -1 감소\n",
    "                        value[j]+=1\n",
    "                    elif agent2[j]==total_agent[i]:\n",
    "                        value[j]-=1\n",
    "                df[f'agent_{total_agent[i]}']=value # 새로운 피처를 데이터프레임에 추가\n",
    "\n",
    "            \n",
    "            df['area']=df['NumRows']*df['NumColumns']\n",
    "            df['row_equal_col']=(df['NumColumns']==df['NumRows']).astype(np.int8)\n",
    "            df['Playouts/Moves'] = df['PlayoutsPerSecond'] / (df['MovesPerSecond'] + 1e-15)\n",
    "            df['EfficiencyPerPlayout'] = df['MovesPerSecond'] / (df['PlayoutsPerSecond'] + 1e-15)\n",
    "            df['TurnsDurationEfficiency'] = df['DurationActions'] / (df['DurationTurnsStdDev'] + 1e-15)\n",
    "            df['AdvantageBalanceRatio'] = df['AdvantageP1'] / (df['Balance'] + 1e-15)\n",
    "            df['ActionTimeEfficiency'] = df['DurationActions'] / (df['MovesPerSecond'] + 1e-15)\n",
    "            df['StandardizedTurnsEfficiency'] = df['DurationTurnsStdDev'] / (df['DurationActions'] + 1e-15)\n",
    "            df['AdvantageTimeImpact'] = df['AdvantageP1'] / (df['DurationActions'] + 1e-15)\n",
    "            df['DurationToComplexityRatio'] = df['DurationActions'] / (df['StateTreeComplexity'] + 1e-15)\n",
    "            df['NormalizedGameTreeComplexity'] =  df['GameTreeComplexity'] /  (df['StateTreeComplexity'] + 1e-15)\n",
    "            df['ComplexityBalanceInteraction'] =  df['Balance'] *  df['GameTreeComplexity']\n",
    "            df['OverallComplexity'] =  df['StateTreeComplexity'] +  df['GameTreeComplexity']\n",
    "            df['ComplexityPerPlayout'] =  df['GameTreeComplexity'] /  (df['PlayoutsPerSecond'] + 1e-15)\n",
    "            df['TurnsNotTimeouts/Moves'] = df['DurationTurnsNotTimeouts'] / (df['MovesPerSecond'] + 1e-15)\n",
    "            df['Timeouts/DurationActions'] = df['Timeouts'] / (df['DurationActions'] + 1e-15)\n",
    "            df['OutcomeUniformity/AdvantageP1'] = df['OutcomeUniformity'] / (df['AdvantageP1'] + 1e-15)\n",
    "            df['ComplexDecisionRatio'] = df['StepDecisionToEnemy'] + df['SlideDecisionToEnemy'] + df['HopDecisionMoreThanOne']\n",
    "            df['AggressiveActionsRatio'] = df['StepDecisionToEnemy'] + df['HopDecisionEnemyToEnemy'] + df['HopDecisionFriendToEnemy'] + df['SlideDecisionToEnemy']\n",
    "            \n",
    "            print(\"deal with outliers\")\n",
    "            df['PlayoutsPerSecond']=df['PlayoutsPerSecond'].clip(0,25000)\n",
    "            df['MovesPerSecond']=df['MovesPerSecond'].clip(0,1000000)\n",
    "            \n",
    "            print(\"agent1 agent2 feature\")\n",
    "            cols=['selection','exploration_const','playout','score_bounds']\n",
    "            for i in range(len(cols)):\n",
    "                for j in range(2):\n",
    "                    df[f'{cols[i]}{j+1}']=df[f'agent{j+1}'].apply(lambda x:x.split('-')[i+1])\n",
    "            \n",
    "\n",
    "            print(f\"one_hot_encoder\")\n",
    "            # One-hot encoding을 적용\n",
    "            # One-hot encoding을 적용할 열과 해당 열의 고유값 리스트\n",
    "            onehot_cols=[['NumOffDiagonalDirections', [0.0, 4.82, 2.0, 5.18, 3.08, 0.06]], ['NumLayers', [1, 0, 4, 5]], ['NumPhasesBoard', [3, 2, 1, 5, 4]], ['NumContainers', [1, 4, 3, 2]], ['NumDice', [0, 2, 1, 4, 6, 3, 5, 7]], ['ProposeDecisionFrequency', [0.0, 0.05, 0.01]], ['PromotionDecisionFrequency', [0.0, 0.01, 0.03, 0.02, 0.11, 0.05, 0.04]], ['SlideDecisionToFriendFrequency', [0.0, 0.19, 0.06]], ['LeapDecisionToEnemyFrequency', [0.0, 0.04, 0.01, 0.02, 0.07, 0.03, 0.14, 0.08]], ['HopDecisionFriendToFriendFrequency', [0.0, 0.13, 0.09]], ['HopDecisionEnemyToEnemyFrequency', [0.0, 0.01, 0.2, 0.03]], ['HopDecisionFriendToEnemyFrequency', [0.0, 0.01, 0.09, 0.25, 0.02]], ['FromToDecisionFrequency', [0.0, 0.38, 1.0, 0.31, 0.94, 0.67]], ['ProposeEffectFrequency', [0.0, 0.01, 0.03]], ['PushEffectFrequency', [0.0, 0.5, 0.96, 0.25]], ['FlipFrequency', [0.0, 0.87, 1.0, 0.96]], ['SetCountFrequency', [0.0, 0.62, 0.54, 0.02]], ['DirectionCaptureFrequency', [0.0, 0.55, 0.54]], ['EncloseCaptureFrequency', [0.0, 0.08, 0.1, 0.07, 0.12, 0.02, 0.09]], ['InterveneCaptureFrequency', [0.0, 0.01, 0.14, 0.04]], ['SurroundCaptureFrequency', [0.0, 0.01, 0.03, 0.02]], ['NumPlayPhase', [1, 2, 3, 4, 5, 6, 7, 8]], ['LineLossFrequency', [0.0, 0.96, 0.87, 0.46, 0.26, 0.88, 0.94]], ['ConnectionEndFrequency', [0.0, 0.19, 1.0, 0.23, 0.94, 0.35, 0.97]], ['ConnectionLossFrequency', [0.0, 0.54, 0.78]], ['GroupEndFrequency', [0.0, 1.0, 0.11, 0.79]], ['GroupWinFrequency', [0.0, 0.11, 1.0]], ['LoopEndFrequency', [0.0, 0.14, 0.66]], ['LoopWinFrequency', [0.0, 0.14, 0.66]], ['PatternEndFrequency', [0.0, 0.63, 0.35]], ['PatternWinFrequency', [0.0, 0.63, 0.35]], ['NoTargetPieceWinFrequency', [0.0, 0.72, 0.77, 0.95, 0.32, 1.0]], ['EliminatePiecesLossFrequency', [0.0, 0.85, 0.96, 0.68]], ['EliminatePiecesDrawFrequency', [0.0, 0.03, 0.91, 1.0, 0.36, 0.86]], ['NoOwnPiecesLossFrequency', [0.0, 1.0, 0.68]], ['FillEndFrequency', [0.0, 1.0, 0.04, 0.01, 0.99, 0.72]], ['FillWinFrequency', [0.0, 1.0, 0.04, 0.01, 0.99]], ['ReachDrawFrequency', [0.0, 0.9, 0.98]], ['ScoringLossFrequency', [0.0, 0.6, 0.62]], ['NoMovesLossFrequency', [0.0, 1.0, 0.13, 0.06]], ['NoMovesDrawFrequency', [0.0, 0.01, 0.04, 0.03, 0.22]], ['BoardSitesOccupiedChangeNumTimes', [0.0, 0.06, 0.42, 0.12, 0.14, 0.94]], ['BranchingFactorChangeNumTimesn', [0.0, 0.3, 0.02, 0.07, 0.04, 0.13, 0.01, 0.21, 0.03]], ['PieceNumberChangeNumTimes', [0.0, 0.06, 0.42, 0.12, 0.14, 1.0]], ['selection1', ['ProgressiveHistory', 'UCB1', 'UCB1GRAVE', 'UCB1Tuned']], ['selection2', ['ProgressiveHistory', 'UCB1GRAVE', 'UCB1', 'UCB1Tuned']], ['exploration_const1', ['0.1', '0.6', '1.41421356237']], ['exploration_const2', ['0.6', '0.1', '1.41421356237']], ['playout1', ['MAST', 'NST', 'Random200']], ['playout2', ['Random200', 'NST', 'MAST']]]\n",
    "            for col,unique in onehot_cols: # 각 열과 고유값에 대해 One-hot encoding\n",
    "                for u in unique:\n",
    "                    df[f'{col}_{u}']=(df[col]==u).astype(np.int8)\n",
    "                    \n",
    "                    \n",
    "            print(\"deal with LudRules\") \n",
    "            print(\"1:drop game\")\n",
    "           # LudRules 열에서 게임 이름을 제거하는 함수 정의\n",
    "            def drop_gamename(rule):\n",
    "                rule=rule[len('(game \"'):]\n",
    "                for i in range(len(rule)):\n",
    "                    if rule[i]=='\"':\n",
    "                        return rule[i+1:]\n",
    "                        # LudRules 열에서 게임 이름 제거\n",
    "            df['LudRules']=df['LudRules'].apply(lambda x:drop_gamename(x))\n",
    "\n",
    "            print(\"2:player\")\n",
    "            # LudRules에서 플레이어 정보를 추출하는 함수 정의\n",
    "            def get_player(rule):\n",
    "                player=''\n",
    "                stack=[]# 괄호와 중괄호의 짝을 맞추기 위한 스택\n",
    "                for i in range(len(rule)):\n",
    "                    player+=rule[i]\n",
    "                    if rule[i] in ['(','{']:\n",
    "                        stack.append(rule[i])  # 여는 괄호는 스택에 추가\n",
    "                    elif rule[i] in [')','}']:\n",
    "                        stack=stack[:-1] # 닫는 괄호는 스택에서 제거\n",
    "                        if len(stack)==0:# 스택이 비면 플레이어 정보 반환\n",
    "                            return player\n",
    "                            # LudRules에서 플레이어 정보 추출 및 데이터프레임에 추가\n",
    "            df['player']=df['LudRules'].apply(lambda rule:get_player(rule))\n",
    "            df=self.clean(df,'player')\n",
    "            # player 열 정리\n",
    "            df['player_len']=df['player'].apply(len) # 결측값 처리 및 소문자로 변환\n",
    "            df['LudRules']=[rule[len(player):] for player,rule in zip(df['player'],df['LudRules'])] # 플레이어 문자열 길이 추가\n",
    "            df.drop(['player'],axis=1,inplace=True) # player 정보를 제외한 나머지 LudRules 값\n",
    "             \n",
    "            print(\"Rules readable\") # player 열 삭제\n",
    "            for rule in ['EnglishRules', 'LudRules']: # LudRules 및 EnglishRules 열에 대해 읽기 점수 계산\n",
    "                df[rule+\"_ARI\"]=df[rule].apply(lambda x:self.ARI(x)) # ARI 점수 계산\n",
    "                df[rule+\"CLRI\"]=df[rule].apply(lambda x:self.CLRI(x)) # CLRI 점수 계산\n",
    "                df[rule+\"McAlpine_EFLAW\"]=df[rule].apply(lambda x:self.McAlpine_EFLAW(x)) # McAlpine EFLAW 점수 계산\n",
    "                    \n",
    "            df['PlayoutsPerSecond/MovesPerSecond']=df['PlayoutsPerSecond']/df['MovesPerSecond']\n",
    "            \n",
    "            # 출현 빈도가 1% 미만인 열 제거\n",
    "            drop_cols=['Cooperation', 'Team', 'TriangleShape', 'DiamondShape', 'SpiralShape', 'StarShape', 'SquarePyramidalShape', 'SemiRegularTiling', 'CircleTiling', 'SpiralTiling', 'MancalaThreeRows', 'MancalaSixRows', 'MancalaCircular', 'AlquerqueBoardWithOneTriangle', 'AlquerqueBoardWithTwoTriangles', 'AlquerqueBoardWithFourTriangles', 'AlquerqueBoardWithEightTriangles', 'ThreeMensMorrisBoard', 'ThreeMensMorrisBoardWithTwoTriangles', 'NineMensMorrisBoard', 'StarBoard', 'PachisiBoard', 'Boardless', 'NumColumns', 'NumCorners', 'NumOffDiagonalDirections', 'NumLayers', 'NumCentreSites', 'NumConvexCorners', 'NumPhasesBoard', 'NumContainers', 'Piece', 'PieceValue', 'PieceRotation', 'PieceDirection', 'LargePiece', 'Tile', 'NumComponentsType', 'NumDice', 'OpeningContract', 'SwapOption', 'Repetition', 'TurnKo', 'PositionalSuperko', 'AutoMove', 'InitialRandomPlacement', 'InitialScore', 'InitialCost', 'Moves', 'VoteDecision', 'SwapPlayersDecision', 'SwapPlayersDecisionFrequency', 'ProposeDecision', 'ProposeDecisionFrequency', 'PromotionDecisionFrequency', 'RotationDecision', 'RotationDecisionFrequency', 'StepDecisionToFriend', 'StepDecisionToFriendFrequency', 'StepDecisionToEnemy', 'SlideDecisionToEnemy', 'SlideDecisionToEnemyFrequency', 'SlideDecisionToFriend', 'SlideDecisionToFriendFrequency', 'LeapDecision', 'LeapDecisionFrequency', 'LeapDecisionToEmpty', 'LeapDecisionToEmptyFrequency', 'LeapDecisionToEnemy', 'LeapDecisionToEnemyFrequency', 'HopDecisionFriendToEmpty', 'HopDecisionFriendToEmptyFrequency', 'HopDecisionFriendToFriendFrequency', 'HopDecisionEnemyToEnemy', 'HopDecisionEnemyToEnemyFrequency', 'HopDecisionFriendToEnemy', 'HopDecisionFriendToEnemyFrequency', 'FromToDecisionFrequency', 'FromToDecisionEnemy', 'FromToDecisionEnemyFrequency', 'FromToDecisionFriend', 'SwapPiecesDecision', 'SwapPiecesDecisionFrequency', 'ShootDecision', 'ShootDecisionFrequency', 'VoteEffect', 'SwapPlayersEffect', 'PassEffect', 'ProposeEffect', 'ProposeEffectFrequency', 'AddEffectFrequency', 'SowFrequency', 'SowCapture', 'SowCaptureFrequency', 'SowRemove', 'SowBacktracking', 'SowBacktrackingFrequency', 'SowProperties', 'SowOriginFirst', 'SowCCW', 'PromotionEffectFrequency', 'PushEffect', 'PushEffectFrequency', 'Flip', 'FlipFrequency', 'SetNextPlayer', 'SetValue', 'SetValueFrequency', 'SetCount', 'SetCountFrequency', 'SetRotation', 'SetRotationFrequency', 'StepEffect', 'SlideEffect', 'LeapEffect', 'ByDieMove', 'MaxDistance', 'ReplacementCaptureFrequency', 'HopCaptureMoreThanOne', 'DirectionCapture', 'DirectionCaptureFrequency', 'EncloseCaptureFrequency', 'CustodialCapture', 'CustodialCaptureFrequency', 'InterveneCapture', 'InterveneCaptureFrequency', 'SurroundCapture', 'SurroundCaptureFrequency', 'CaptureSequence', 'CaptureSequenceFrequency', 'Group', 'Loop', 'Pattern', 'PathExtent', 'Territory', 'Fill', 'CanNotMove', 'Threat', 'CountPiecesMoverComparison', 'ProgressCheck', 'RotationalDirection', 'SameLayerDirection', 'ForwardDirection', 'BackwardDirection', 'BackwardsDirection', 'LeftwardDirection', 'RightwardsDirection', 'LeftwardsDirection', 'ForwardLeftDirection', 'ForwardRightDirection', 'BackwardLeftDirection', 'BackwardRightDirection', 'SameDirection', 'OppositeDirection', 'NumPlayPhase', 'LineLoss', 'LineLossFrequency', 'LineDraw', 'ConnectionEnd', 'ConnectionEndFrequency', 'ConnectionWinFrequency', 'ConnectionLoss', 'ConnectionLossFrequency', 'GroupEnd', 'GroupEndFrequency', 'GroupWin', 'GroupWinFrequency', 'GroupLoss', 'GroupDraw', 'LoopEnd', 'LoopEndFrequency', 'LoopWin', 'LoopWinFrequency', 'LoopLoss', 'PatternEnd', 'PatternEndFrequency', 'PatternWin', 'PatternWinFrequency', 'PathExtentEnd', 'PathExtentWin', 'PathExtentLoss', 'TerritoryEnd', 'TerritoryWin', 'TerritoryWinFrequency', 'Checkmate', 'CheckmateWin', 'NoTargetPieceEndFrequency', 'NoTargetPieceWin', 'NoTargetPieceWinFrequency', 'EliminatePiecesLoss', 'EliminatePiecesLossFrequency', 'EliminatePiecesDraw', 'EliminatePiecesDrawFrequency', 'NoOwnPiecesEnd', 'NoOwnPiecesWin', 'NoOwnPiecesLoss', 'NoOwnPiecesLossFrequency', 'FillEnd', 'FillEndFrequency', 'FillWin', 'FillWinFrequency', 'ReachWin', 'ReachLoss', 'ReachLossFrequency', 'ReachDraw', 'ReachDrawFrequency', 'ScoringLoss', 'ScoringLossFrequency', 'ScoringDraw', 'NoMovesLoss', 'NoMovesDrawFrequency', 'NoProgressEnd', 'NoProgressEndFrequency', 'NoProgressDraw', 'NoProgressDrawFrequency', 'BoardCoverageFull', 'BoardSitesOccupiedChangeNumTimes', 'BranchingFactorChangeLineBestFit', 'BranchingFactorChangeNumTimesn', 'DecisionFactorChangeNumTimes', 'MoveDistanceChangeSign', 'MoveDistanceChangeLineBestFit', 'PieceNumberChangeNumTimes', 'PieceNumberMaxIncrease', 'ScoreDifferenceMedian', 'ScoreDifferenceVariance', 'ScoreDifferenceChangeAverage', 'ScoreDifferenceChangeSign', 'ScoreDifferenceChangeLineBestFit', 'Math', 'Division', 'Modulo', 'Absolute', 'Exponentiation', 'Minimum', 'Maximum', 'Even', 'Odd', 'Visual', 'GraphStyle', 'MancalaStyle', 'PenAndPaperStyle', 'ShibumiStyle', 'BackgammonStyle', 'JanggiStyle', 'XiangqiStyle', 'ShogiStyle', 'TableStyle', 'SurakartaStyle', 'NoBoard', 'ChessComponent', 'KingComponent', 'QueenComponent', 'KnightComponent', 'RookComponent', 'BishopComponent', 'PawnComponent', 'FairyChessComponent', 'PloyComponent', 'ShogiComponent', 'XiangqiComponent', 'StrategoComponent', 'JanggiComponent', 'TaflComponent', 'StackType', 'Stack', 'ShowPieceValue', 'ShowPieceState', 'Implementation', 'StateType', 'StackState', 'VisitedSites', 'InternalCounter', 'SetInternalCounter', 'Efficiency', 'NumOffDiagonalDirections_0.0', 'NumOffDiagonalDirections_4.82', 'NumOffDiagonalDirections_2.0', 'NumOffDiagonalDirections_5.18', 'NumOffDiagonalDirections_3.08', 'NumOffDiagonalDirections_0.06', 'NumLayers_1', 'NumLayers_0', 'NumLayers_4', 'NumLayers_5', 'NumPhasesBoard_1', 'NumPhasesBoard_5', 'NumDice_0', 'NumDice_2', 'NumDice_6', 'NumDice_3', 'NumDice_5', 'NumDice_7', 'ProposeDecisionFrequency_0.0', 'ProposeDecisionFrequency_0.05', 'ProposeDecisionFrequency_0.01', 'PromotionDecisionFrequency_0.0', 'PromotionDecisionFrequency_0.01', 'PromotionDecisionFrequency_0.03', 'PromotionDecisionFrequency_0.02', 'PromotionDecisionFrequency_0.11', 'PromotionDecisionFrequency_0.05', 'PromotionDecisionFrequency_0.04', 'SlideDecisionToFriendFrequency_0.0', 'SlideDecisionToFriendFrequency_0.19', 'SlideDecisionToFriendFrequency_0.06', 'LeapDecisionToEnemyFrequency_0.0', 'LeapDecisionToEnemyFrequency_0.04', 'LeapDecisionToEnemyFrequency_0.01', 'LeapDecisionToEnemyFrequency_0.02', 'LeapDecisionToEnemyFrequency_0.07', 'LeapDecisionToEnemyFrequency_0.03', 'LeapDecisionToEnemyFrequency_0.14', 'LeapDecisionToEnemyFrequency_0.08', 'HopDecisionFriendToFriendFrequency_0.0', 'HopDecisionFriendToFriendFrequency_0.13', 'HopDecisionFriendToFriendFrequency_0.09', 'HopDecisionEnemyToEnemyFrequency_0.0', 'HopDecisionEnemyToEnemyFrequency_0.01', 'HopDecisionEnemyToEnemyFrequency_0.2', 'HopDecisionEnemyToEnemyFrequency_0.03', 'HopDecisionFriendToEnemyFrequency_0.0', 'HopDecisionFriendToEnemyFrequency_0.01', 'HopDecisionFriendToEnemyFrequency_0.09', 'HopDecisionFriendToEnemyFrequency_0.25', 'HopDecisionFriendToEnemyFrequency_0.02', 'FromToDecisionFrequency_0.0', 'FromToDecisionFrequency_0.38', 'FromToDecisionFrequency_1.0', 'FromToDecisionFrequency_0.31', 'FromToDecisionFrequency_0.94', 'FromToDecisionFrequency_0.67', 'ProposeEffectFrequency_0.0', 'ProposeEffectFrequency_0.01', 'ProposeEffectFrequency_0.03', 'PushEffectFrequency_0.0', 'PushEffectFrequency_0.5', 'PushEffectFrequency_0.96', 'PushEffectFrequency_0.25', 'FlipFrequency_0.0', 'FlipFrequency_0.87', 'FlipFrequency_1.0', 'FlipFrequency_0.96', 'SetCountFrequency_0.0', 'SetCountFrequency_0.62', 'SetCountFrequency_0.54', 'SetCountFrequency_0.02', 'DirectionCaptureFrequency_0.0', 'DirectionCaptureFrequency_0.55', 'DirectionCaptureFrequency_0.54', 'EncloseCaptureFrequency_0.0', 'EncloseCaptureFrequency_0.08', 'EncloseCaptureFrequency_0.1', 'EncloseCaptureFrequency_0.07', 'EncloseCaptureFrequency_0.12', 'EncloseCaptureFrequency_0.02', 'EncloseCaptureFrequency_0.09', 'InterveneCaptureFrequency_0.0', 'InterveneCaptureFrequency_0.01', 'InterveneCaptureFrequency_0.14', 'InterveneCaptureFrequency_0.04', 'SurroundCaptureFrequency_0.0', 'SurroundCaptureFrequency_0.01', 'SurroundCaptureFrequency_0.03', 'SurroundCaptureFrequency_0.02', 'NumPlayPhase_3', 'NumPlayPhase_4', 'NumPlayPhase_5', 'NumPlayPhase_6', 'NumPlayPhase_7', 'NumPlayPhase_8', 'LineLossFrequency_0.0', 'LineLossFrequency_0.96', 'LineLossFrequency_0.87', 'LineLossFrequency_0.46', 'LineLossFrequency_0.26', 'LineLossFrequency_0.88', 'LineLossFrequency_0.94', 'ConnectionEndFrequency_0.0', 'ConnectionEndFrequency_0.19', 'ConnectionEndFrequency_1.0', 'ConnectionEndFrequency_0.23', 'ConnectionEndFrequency_0.94', 'ConnectionEndFrequency_0.35', 'ConnectionEndFrequency_0.97', 'ConnectionLossFrequency_0.0', 'ConnectionLossFrequency_0.54', 'ConnectionLossFrequency_0.78', 'GroupEndFrequency_0.0', 'GroupEndFrequency_1.0', 'GroupEndFrequency_0.11', 'GroupEndFrequency_0.79', 'GroupWinFrequency_0.0', 'GroupWinFrequency_0.11', 'GroupWinFrequency_1.0', 'LoopEndFrequency_0.0', 'LoopEndFrequency_0.14', 'LoopEndFrequency_0.66', 'LoopWinFrequency_0.0', 'LoopWinFrequency_0.14', 'LoopWinFrequency_0.66', 'PatternEndFrequency_0.0', 'PatternEndFrequency_0.63', 'PatternEndFrequency_0.35', 'PatternWinFrequency_0.0', 'PatternWinFrequency_0.63', 'PatternWinFrequency_0.35', 'NoTargetPieceWinFrequency_0.0', 'NoTargetPieceWinFrequency_0.72', 'NoTargetPieceWinFrequency_0.77', 'NoTargetPieceWinFrequency_0.95', 'NoTargetPieceWinFrequency_0.32', 'NoTargetPieceWinFrequency_1.0', 'EliminatePiecesLossFrequency_0.0', 'EliminatePiecesLossFrequency_0.85', 'EliminatePiecesLossFrequency_0.96', 'EliminatePiecesLossFrequency_0.68', 'EliminatePiecesDrawFrequency_0.0', 'EliminatePiecesDrawFrequency_0.03', 'EliminatePiecesDrawFrequency_0.91', 'EliminatePiecesDrawFrequency_1.0', 'EliminatePiecesDrawFrequency_0.36', 'EliminatePiecesDrawFrequency_0.86', 'NoOwnPiecesLossFrequency_0.0', 'NoOwnPiecesLossFrequency_1.0', 'NoOwnPiecesLossFrequency_0.68', 'FillEndFrequency_0.0', 'FillEndFrequency_1.0', 'FillEndFrequency_0.04', 'FillEndFrequency_0.01', 'FillEndFrequency_0.99', 'FillEndFrequency_0.72', 'FillWinFrequency_0.0', 'FillWinFrequency_1.0', 'FillWinFrequency_0.04', 'FillWinFrequency_0.01', 'FillWinFrequency_0.99', 'ReachDrawFrequency_0.0', 'ReachDrawFrequency_0.9', 'ReachDrawFrequency_0.98', 'ScoringLossFrequency_0.0', 'ScoringLossFrequency_0.6', 'ScoringLossFrequency_0.62', 'NoMovesLossFrequency_0.0', 'NoMovesLossFrequency_1.0', 'NoMovesLossFrequency_0.13', 'NoMovesLossFrequency_0.06', 'NoMovesDrawFrequency_0.0', 'NoMovesDrawFrequency_0.01', 'NoMovesDrawFrequency_0.04', 'NoMovesDrawFrequency_0.03', 'NoMovesDrawFrequency_0.22', 'BoardSitesOccupiedChangeNumTimes_0.0', 'BoardSitesOccupiedChangeNumTimes_0.06', 'BoardSitesOccupiedChangeNumTimes_0.42', 'BoardSitesOccupiedChangeNumTimes_0.12', 'BoardSitesOccupiedChangeNumTimes_0.14', 'BoardSitesOccupiedChangeNumTimes_0.94', 'BranchingFactorChangeNumTimesn_0.0', 'BranchingFactorChangeNumTimesn_0.3', 'BranchingFactorChangeNumTimesn_0.02', 'BranchingFactorChangeNumTimesn_0.07', 'BranchingFactorChangeNumTimesn_0.04', 'BranchingFactorChangeNumTimesn_0.13', 'BranchingFactorChangeNumTimesn_0.01', 'BranchingFactorChangeNumTimesn_0.21', 'BranchingFactorChangeNumTimesn_0.03', 'PieceNumberChangeNumTimes_0.0', 'PieceNumberChangeNumTimes_0.06', 'PieceNumberChangeNumTimes_0.42', 'PieceNumberChangeNumTimes_0.12', 'PieceNumberChangeNumTimes_0.14', 'PieceNumberChangeNumTimes_1.0', 'KintsBoard', 'FortyStonesWithFourGapsBoard', 'Roll', 'SumDice', 'CheckmateFrequency', 'NumDice_4']\n",
    "            \n",
    "            df.drop(['Id',\n",
    "            # 모든 값이 동일한 열 제거\n",
    "            'Properties', 'Format', 'Time', 'Discrete', 'Realtime', 'Turns', 'Alternating', 'Simultaneous', 'HiddenInformation', 'Match', 'AsymmetricRules', 'AsymmetricPlayRules', 'AsymmetricEndRules', 'AsymmetricSetup', 'Players', 'NumPlayers', 'Simulation', 'Solitaire', 'TwoPlayer', 'Multiplayer', 'Coalition', 'Puzzle', 'DeductionPuzzle', 'PlanningPuzzle', 'Equipment', 'Container', 'Board', 'PrismShape', 'ParallelogramShape', 'RectanglePyramidalShape', 'TargetShape', 'BrickTiling', 'CelticTiling', 'QuadHexTiling', 'Hints', 'PlayableSites', 'Component', 'DiceD3', 'BiasedDice', 'Card', 'Domino', 'Rules', 'SituationalTurnKo', 'SituationalSuperko', 'InitialAmount', 'InitialPot', 'Play', 'BetDecision', 'BetDecisionFrequency', 'VoteDecisionFrequency', 'ChooseTrumpSuitDecision', 'ChooseTrumpSuitDecisionFrequency', 'LeapDecisionToFriend', 'LeapDecisionToFriendFrequency', 'HopDecisionEnemyToFriend', 'HopDecisionEnemyToFriendFrequency', 'HopDecisionFriendToFriend', 'FromToDecisionWithinBoard', 'FromToDecisionBetweenContainers', 'BetEffect', 'BetEffectFrequency', 'VoteEffectFrequency', 'SwapPlayersEffectFrequency', 'TakeControl', 'TakeControlFrequency', 'PassEffectFrequency', 'SetCost', 'SetCostFrequency', 'SetPhase', 'SetPhaseFrequency', 'SetTrumpSuit', 'SetTrumpSuitFrequency', 'StepEffectFrequency', 'SlideEffectFrequency', 'LeapEffectFrequency', 'HopEffectFrequency', 'FromToEffectFrequency', 'SwapPiecesEffect', 'SwapPiecesEffectFrequency', 'ShootEffect', 'ShootEffectFrequency', 'MaxCapture', 'OffDiagonalDirection', 'Information', 'HidePieceType', 'HidePieceOwner', 'HidePieceCount', 'HidePieceRotation', 'HidePieceValue', 'HidePieceState', 'InvisiblePiece', 'End', 'LineDrawFrequency', 'ConnectionDraw', 'ConnectionDrawFrequency', 'GroupLossFrequency', 'GroupDrawFrequency', 'LoopLossFrequency', 'LoopDraw', 'LoopDrawFrequency', 'PatternLoss', 'PatternLossFrequency', 'PatternDraw', 'PatternDrawFrequency', 'PathExtentEndFrequency', 'PathExtentWinFrequency', 'PathExtentLossFrequency', 'PathExtentDraw', 'PathExtentDrawFrequency', 'TerritoryLoss', 'TerritoryLossFrequency', 'TerritoryDraw', 'TerritoryDrawFrequency', 'CheckmateLoss', 'CheckmateLossFrequency', 'CheckmateDraw', 'CheckmateDrawFrequency', 'NoTargetPieceLoss', 'NoTargetPieceLossFrequency', 'NoTargetPieceDraw', 'NoTargetPieceDrawFrequency', 'NoOwnPiecesDraw', 'NoOwnPiecesDrawFrequency', 'FillLoss', 'FillLossFrequency', 'FillDraw', 'FillDrawFrequency', 'ScoringDrawFrequency', 'NoProgressWin', 'NoProgressWinFrequency', 'NoProgressLoss', 'NoProgressLossFrequency', 'SolvedEnd', 'Behaviour', 'StateRepetition', 'PositionalRepetition', 'SituationalRepetition', 'Duration', 'Complexity', 'BoardCoverage', 'GameOutcome', 'StateEvaluation', 'Clarity', 'Narrowness', 'Variance', 'Decisiveness', 'DecisivenessMoves', 'DecisivenessThreshold', 'LeadChange', 'Stability', 'Drama', 'DramaAverage', 'DramaMedian', 'DramaMaximum', 'DramaMinimum', 'DramaVariance', 'DramaChangeAverage', 'DramaChangeSign', 'DramaChangeLineBestFit', 'DramaChangeNumTimes', 'DramaMaxIncrease', 'DramaMaxDecrease', 'MoveEvaluation', 'MoveEvaluationAverage', 'MoveEvaluationMedian', 'MoveEvaluationMaximum', 'MoveEvaluationMinimum', 'MoveEvaluationVariance', 'MoveEvaluationChangeAverage', 'MoveEvaluationChangeSign', 'MoveEvaluationChangeLineBestFit', 'MoveEvaluationChangeNumTimes', 'MoveEvaluationMaxIncrease', 'MoveEvaluationMaxDecrease', 'StateEvaluationDifference', 'StateEvaluationDifferenceAverage', 'StateEvaluationDifferenceMedian', 'StateEvaluationDifferenceMaximum', 'StateEvaluationDifferenceMinimum', 'StateEvaluationDifferenceVariance', 'StateEvaluationDifferenceChangeAverage', 'StateEvaluationDifferenceChangeSign', 'StateEvaluationDifferenceChangeLineBestFit', 'StateEvaluationDifferenceChangeNumTimes', 'StateEvaluationDifferenceMaxIncrease', 'StateEvaluationDifferenceMaxDecrease', 'BoardSitesOccupied', 'BoardSitesOccupiedMinimum', 'BranchingFactor', 'BranchingFactorMinimum', 'DecisionFactor', 'DecisionFactorMinimum', 'MoveDistance', 'MoveDistanceMinimum', 'PieceNumber', 'PieceNumberMinimum', 'ScoreDifference', 'ScoreDifferenceMinimum', 'ScoreDifferenceChangeNumTimes', 'Roots', 'Cosine', 'Sine', 'Tangent', 'Exponential', 'Logarithm', 'ExclusiveDisjunction', 'Float', 'HandComponent', 'SetHidden', 'SetInvisible', 'SetHiddenCount', 'SetHiddenRotation', 'SetHiddenState', 'SetHiddenValue', 'SetHiddenWhat', 'SetHiddenWho',\n",
    "            # 훈련 데이터에만 존재하는 열 제거\n",
    "            'num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1',\n",
    "            #object\n",
    "            'Behaviour', 'StateRepetition', 'Duration', 'Complexity', 'BoardCoverage', 'GameOutcome', 'StateEvaluation', 'Clarity', 'Decisiveness', 'Drama', 'MoveEvaluation', 'StateEvaluationDifference', 'BoardSitesOccupied', 'BranchingFactor', 'DecisionFactor', 'MoveDistance', 'PieceNumber', 'ScoreDifference','selection1', 'selection2', 'exploration_const1', 'exploration_const2', 'playout1', 'playout2', 'score_bounds1', 'score_bounds2',\n",
    "            ]+drop_cols,axis=1,inplace=True,errors='ignore')#对于测试集中没有的列可以直接忽略 \n",
    "            \n",
    "            df=self.reduce_mem_usage(df)\n",
    "            print(f\"feature_count:{len(df.columns)}\")\n",
    "            print(\"-\"*30)\n",
    "            return df\n",
    "\n",
    "        def CV_feats(self,df,mode='',model_name='',fold=0):\n",
    "            str_cols=['EnglishRules', 'LudRules']#'agent1','agent2',\n",
    "            for col in str_cols:\n",
    "                df=self.clean(df,col)\n",
    "                df[f'{col}_len']=df[col].apply(len)\n",
    "                if mode=='train':\n",
    "                    tfidf = TfidfVectorizer(max_features=500,ngram_range=(2,3))\n",
    "                    tfidf_feats=tfidf.fit_transform(df[col]).toarray()\n",
    "                    for i in range(tfidf_feats.shape[1]):\n",
    "                        df[f\"{col}_tfidf_{i}\"]=tfidf_feats[:,i]\n",
    "                    self.pickle_dump(tfidf,f'{model_name}_{fold}_{col}tfidf.model')\n",
    "                    self.tfidf_paths.append((model_name,fold,col))\n",
    "                else:#mode=='test'\n",
    "                    for i in range(len(self.tfidf_paths)):\n",
    "                        if (model_name,fold,col)==self.tfidf_paths[i]:\n",
    "                            tfidf=self.pickle_load(f'{model_name}_{fold}_{col}tfidf.model')\n",
    "                            tfidf_feats=tfidf.transform(df[col]).toarray()\n",
    "                            for j in range(tfidf_feats.shape[1]):\n",
    "                                df[f\"{col}_tfidf_{j}\"]=tfidf_feats[:,j]\n",
    "            df.drop(str_cols+['agent1','agent2'],axis=1,inplace=True)\n",
    "            return df \n",
    "        \n",
    "        def RMSE(self,y_true,y_pred):\n",
    "            return np.sqrt(np.mean((y_true-y_pred)**2))\n",
    "        \n",
    "        def train_model(self,):\n",
    "            self.train=self.FE(self.train,mode='train')\n",
    "            #https://www.kaggle.com/code/ravi20076/mcts2024-mlmodels-v1/notebook\n",
    "            cat_params1={\n",
    "                'task_type'           : \"GPU\",\n",
    "                'eval_metric'         : \"RMSE\",\n",
    "                'bagging_temperature' : 0.50,\n",
    "                'iterations'          : 100 if APP.small_iterations else 3096,\n",
    "                'learning_rate'       : 0.08,\n",
    "                'max_depth'           : 12,\n",
    "                'l2_leaf_reg'         : 1.25,\n",
    "                'min_data_in_leaf'    : 24,\n",
    "                'random_strength'     : 0.25, \n",
    "                'verbose'             : 0,\n",
    "                }\n",
    "            \n",
    "            cat_params2={\n",
    "                'task_type'           : \"GPU\",\n",
    "                'eval_metric'         : \"RMSE\",\n",
    "                'bagging_temperature' : 0.60,\n",
    "                'iterations'          : 100 if APP.small_iterations else 3096,\n",
    "                'learning_rate'       : 0.08,\n",
    "                'max_depth'           : 12,\n",
    "                'l2_leaf_reg'         : 1.25,\n",
    "                'min_data_in_leaf'    : 24,\n",
    "                'random_strength'     : 0.20, \n",
    "                'max_bin'             :2048,\n",
    "                'verbose'             : 0,\n",
    "                }\n",
    "            models=[\n",
    "                    (CatBoostRegressor(**cat_params1),'cat1'),\n",
    "                    (CatBoostRegressor(**cat_params2),'cat2'),\n",
    "                ]\n",
    "            if APP.short_dataset:\n",
    "                self.train = self.train[:1000]\n",
    "            for (model,model_name) in models:\n",
    "                print(\"start training\")\n",
    "                X=self.train.drop([self.target,'GameRulesetName'],axis=1)\n",
    "                GameRulesetName=self.train['GameRulesetName']\n",
    "                y=self.train[self.target]\n",
    "                oof_preds=np.zeros(len(X))\n",
    "                \n",
    "                y_int=round(y*15)\n",
    "                \n",
    "                sgkf = StratifiedGroupKFold(n_splits=self.num_folds,random_state=2024,shuffle=True)\n",
    "\n",
    "                for fold, (train_index, valid_index) in (enumerate(sgkf.split(X,y_int,GameRulesetName))):\n",
    "                    print(f\"fold:{fold}\")\n",
    "\n",
    "                    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "                    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "                    X_train=self.CV_feats(X_train,mode='train',model_name=model_name,fold=fold)\n",
    "                    X_valid=self.CV_feats(X_valid,mode='test',model_name=model_name,fold=fold)\n",
    "\n",
    "                    model.fit(X_train, y_train,\n",
    "                        eval_set=(X_valid, y_valid),\n",
    "                        early_stopping_rounds=100, verbose=100)\n",
    "                    \n",
    "                    oof_preds[valid_index]=model.predict(X_valid)\n",
    "\n",
    "                    self.pickle_dump(model,f'{model_name}_{fold}.model')\n",
    "                    self.model_paths.append((model_name,fold))\n",
    "\n",
    "                    del X_train,X_valid,y_train,y_valid\n",
    "                    gc.collect()\n",
    "                \n",
    "                np.save(f\"{model_name}_oof.npy\",np.clip(oof_preds*1.1,-0.985,0.985))\n",
    "                \n",
    "                print(f\"RMSE:{self.RMSE(y.values,np.clip(oof_preds*1.1,-0.985,0.985) )}\")\n",
    "                \n",
    "        def infer_model(self,test):\n",
    "            test=self.FE(test,mode='test')\n",
    "            test.drop(['GameRulesetName'],axis=1,inplace=True)\n",
    "            test_preds=[]\n",
    "            for i in range(len(self.model_paths)):\n",
    "                model_name,fold=self.model_paths[i]\n",
    "                test_copy=self.CV_feats(test.copy(),mode='test',model_name=model_name,fold=fold)\n",
    "                model=self.pickle_load(f'{model_name}_{fold}.model')\n",
    "                test_preds+=[np.clip(model.predict(test_copy)*1.1,-0.985,0.985)]\n",
    "            return np.mean(test_preds,axis=0)\n",
    "        \n",
    "    preprocessor=Preprocessor(num_folds=5,train=train)\n",
    "    counter = 0\n",
    "    def predict(test, submission):\n",
    "        if model_1.counter == 0:\n",
    "            model_1.preprocessor.train_model()  \n",
    "        model_1.counter += 1\n",
    "        return model_1.preprocessor.infer_model(test.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# **》》》Model2**\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T00:38:52.375960Z",
     "iopub.status.busy": "2024-11-29T00:38:52.375562Z",
     "iopub.status.idle": "2024-11-29T00:38:52.403084Z",
     "shell.execute_reply": "2024-11-29T00:38:52.402037Z",
     "shell.execute_reply.started": "2024-11-29T00:38:52.375919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class model_2:\n",
    "    class CFG:\n",
    "        importances_path = Path('/kaggle/input/mcts-gbdt-select-200-features/importances.csv')    \n",
    "        train_path = Path('/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv')\n",
    "        batch_size = 65536\n",
    "\n",
    "        early_stop = 500\n",
    "        n_splits = 5\n",
    "        color = '#C9A9A6'\n",
    "        \n",
    "        lgb_w = 0.85\n",
    "        lgb_p = {\n",
    "            'objective': 'regression',\n",
    "            'min_child_samples': 24,\n",
    "            'num_iterations': 200 if APP.small_iterations else 20000,\n",
    "            'learning_rate': 0.07,\n",
    "            'extra_trees': True,\n",
    "            'reg_lambda': 0.8,\n",
    "            'reg_alpha': 0.1,\n",
    "            'num_leaves': 64,\n",
    "            'metric': 'rmse',\n",
    "            'device': 'CPU',\n",
    "            'max_depth': 24,\n",
    "            'max_bin': 128,\n",
    "            'verbose': -1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        ctb_w = 0.25\n",
    "        ctb_p = {\n",
    "            'loss_function': 'RMSE',\n",
    "            'learning_rate': 0.03,\n",
    "            'num_trees': 200 if APP.small_iterations else 20000,\n",
    "            'random_state': 42,\n",
    "            'task_type': 'CPU',\n",
    "            'reg_lambda': 0.8,\n",
    "            'depth': 8\n",
    "        }\n",
    "\n",
    "    class FE:\n",
    "        def __init__(self, batch_size):\n",
    "            self.batch_size = batch_size\n",
    "            \n",
    "        def drop_cols(self, df, bad_cols=None): # bad_cols must be provided when processing the test data\n",
    "            # Define redundant columns for model development\n",
    "            cols = ['Id', \n",
    "                    'LudRules', \n",
    "                    'EnglishRules',\n",
    "                    'num_wins_agent1',\n",
    "                    'num_draws_agent1',\n",
    "                    'num_losses_agent1']\n",
    "            \n",
    "            df = df.drop([col for col in cols if col in df.columns])\n",
    "            \n",
    "            # Select and drop columns with 100% null values\n",
    "            df = df.drop([col for col in df.columns if df.select(pl.col(col).null_count()).item() == df.height])\n",
    "            \n",
    "            # Select (if not provided) and drop columns with only one unique value\n",
    "            bad_cols = [col for col in df.columns if df.select(pl.col(col).n_unique()).item() == 1] if bad_cols is None else bad_cols\n",
    "            df = df.drop(bad_cols)\n",
    "            return df, bad_cols\n",
    "        \n",
    "        def cast_datatypes(self, df):\n",
    "            # Set datatype for categorical columns\n",
    "            cat_cols = ['GameRulesetName', 'agent1', 'agent2']\n",
    "            df = df.with_columns([pl.col(col).cast(pl.String) for col in cat_cols])   \n",
    "            \n",
    "            # Find numeric columns\n",
    "            for col in df.columns:\n",
    "                if col not in cat_cols:\n",
    "                    # Set datatype for a numeric column as per the datatype of the first non-null item\n",
    "                    val = df.select(pl.col(col).drop_nulls().first()).item()\n",
    "                    df = df.with_columns(pl.col(col).cast(pl.Int16) if isinstance(val, int) else pl.col(col).cast(pl.Float32))   \n",
    "            return df    \n",
    "        \n",
    "        def info(self, df):\n",
    "            print(f'Shape: {df.shape}')   \n",
    "            mem = df.estimated_size() / 1024**2\n",
    "            print('Memory usage: {:.2f} MB\\n'.format(mem))\n",
    "            \n",
    "        def apply_fe(self, path):            \n",
    "            df = pl.read_csv(path, batch_size=self.batch_size)\n",
    "            df, bad_cols = self.drop_cols(df)\n",
    "            df = self.cast_datatypes(df)\n",
    "            self.info(df)\n",
    "            cat_cols = [col for col in df.columns if df[col].dtype == pl.String]\n",
    "            return df, bad_cols, cat_cols\n",
    "\n",
    "    fe = FE(CFG.batch_size)\n",
    "\n",
    "    class MD:\n",
    "        def __init__(self, \n",
    "                    importances_path, \n",
    "                    early_stop, \n",
    "                    n_splits, \n",
    "                    lgb_w, \n",
    "                    lgb_p, \n",
    "                    ctb_w, \n",
    "                    ctb_p, \n",
    "                    color):\n",
    "            self.importances_path = importances_path\n",
    "            self.early_stop = early_stop\n",
    "            self.n_splits = n_splits\n",
    "            self.lgb_w = lgb_w\n",
    "            self.lgb_p = lgb_p\n",
    "            self.ctb_w = ctb_w\n",
    "            self.ctb_p = ctb_p\n",
    "            self.color = color\n",
    "            \n",
    "        def plot_cv(self, fold_scores, title):\n",
    "            fold_scores = [round(score, 3) for score in fold_scores]\n",
    "            mean_score = round(np.mean(fold_scores), 3)\n",
    "            std_score = round(np.std(fold_scores), 3)\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x = list(range(1, len(fold_scores) + 1)),\n",
    "                y = fold_scores,\n",
    "                mode = 'markers', \n",
    "                name = 'Fold Scores',\n",
    "                marker = dict(size = 24, color=self.color, symbol='diamond'),\n",
    "                text = [f'{score:.3f}' for score in fold_scores],\n",
    "                hovertemplate = 'Fold %{x}: %{text}<extra></extra>',\n",
    "                hoverlabel=dict(font=dict(size=16))  \n",
    "            ))\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x = [1, len(fold_scores)],\n",
    "                y = [mean_score, mean_score],\n",
    "                mode = 'lines',\n",
    "                name = f'Mean: {mean_score:.3f}',\n",
    "                line = dict(dash = 'dash', color = '#FFBF00'),\n",
    "                hoverinfo = 'none'\n",
    "            ))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title = f'{title} | Cross-Validation RMSE Scores | Variation of CV scores: {mean_score} ± {std_score}',\n",
    "                xaxis_title = 'Fold',\n",
    "                yaxis_title = 'RMSE Score',\n",
    "                plot_bgcolor = 'rgba(0,0,0,0)',\n",
    "                paper_bgcolor = 'rgba(0,0,0,0)',\n",
    "                xaxis = dict(\n",
    "                    gridcolor = 'lightgray',\n",
    "                    tickmode = 'linear',\n",
    "                    tick0 = 1,\n",
    "                    dtick = 1,\n",
    "                    range = [0.5, len(fold_scores) + 0.5]\n",
    "                ),\n",
    "                yaxis = dict(gridcolor = 'lightgray')\n",
    "            )\n",
    "            fig.show() \n",
    "            \n",
    "        def train_model(self, data, cat_cols, title):\n",
    "            importances = pd.read_csv(self.importances_path)\n",
    "            \n",
    "            for col in cat_cols:\n",
    "                data[col] = data[col].astype('category')\n",
    "            \n",
    "            # Define features (X), label (y) and grouping column (group) for CV\n",
    "            X = data.drop(['utility_agent1'], axis=1)\n",
    "            y = data['utility_agent1']\n",
    "            group = data['GameRulesetName']\n",
    "            y_int=round(y*15)\n",
    "            cv = StratifiedGroupKFold(n_splits=self.n_splits)\n",
    "            models, scores = [], []\n",
    "            \n",
    "            # Initialize out-of-fold predictions array\n",
    "            oof_preds = np.zeros(len(X))\n",
    "            \n",
    "            for fold, (train_index, valid_index) in enumerate(cv.split(X, y_int, group)):\n",
    "                drop_features = importances['drop_features'].tolist()\n",
    "                X_train, X_valid = X.iloc[train_index].drop(drop_features, axis=1), X.iloc[valid_index].drop(drop_features, axis=1)\n",
    "                y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "                print(f'Fold {fold+1} | {X_train.shape[0]:,} train rows | {X_valid.shape[0]:,} valid rows | {X_train.shape[1]} features')\n",
    "                    \n",
    "                if title.startswith('LightGBM'):\n",
    "                    model = lgb.LGBMRegressor(**self.lgb_p)\n",
    "\n",
    "                    model.fit(X_train, y_train,\n",
    "                            eval_set=[(X_valid, y_valid)],\n",
    "                            eval_metric='rmse',\n",
    "                            callbacks=[lgb.early_stopping(self.early_stop, verbose=0), lgb.log_evaluation(0)])\n",
    "                \n",
    "                elif title.startswith('CatBoost'):\n",
    "                    model = CatBoostRegressor(**self.ctb_p, verbose=0, cat_features=cat_cols)\n",
    "\n",
    "                    model.fit(X_train, y_train,\n",
    "                            eval_set=(X_valid, y_valid),\n",
    "                            early_stopping_rounds=self.early_stop, verbose=0)\n",
    "\n",
    "                models.append(model)\n",
    "\n",
    "                # Store out-of-fold predictions for this fold\n",
    "                oof_preds[valid_index] = model.predict(X_valid)\n",
    "                score = mse(y_valid, oof_preds[valid_index], squared=False)\n",
    "                scores.append(score)\n",
    "            \n",
    "            self.plot_cv(scores, title)\n",
    "            return models, oof_preds\n",
    "        \n",
    "        def inference(self, data, cat_cols, lgb_models, ctb_models, lgb_models_oof, ctb_models_oof):\n",
    "            importances = pd.read_csv(self.importances_path)\n",
    "                \n",
    "            drop_features = importances['drop_features'].tolist()\n",
    "            data = data.drop(drop_features, axis=1)\n",
    "\n",
    "            for col in cat_cols:\n",
    "                data[col] = data[col].astype('category')\n",
    "                    \n",
    "            data['lgb_oof_preds'] = np.mean([model.predict(data) for model in lgb_models], axis=0)\n",
    "            data['ctb_oof_preds'] = np.mean([model.predict(data) for model in ctb_models], axis=0)\n",
    "            \n",
    "            lgb_preds = np.mean([model.predict(data) for model in lgb_models_oof], axis=0)  \n",
    "            ctb_preds = np.mean([model.predict(data) for model in ctb_models_oof], axis=0)    \n",
    "            \n",
    "            return lgb_preds * self.lgb_w + ctb_preds * self.ctb_w\n",
    "        \n",
    "    md = MD(CFG.importances_path, \n",
    "            CFG.early_stop, \n",
    "            CFG.n_splits, \n",
    "            CFG.lgb_w, \n",
    "            CFG.lgb_p, \n",
    "            CFG.ctb_w, \n",
    "            CFG.ctb_p, \n",
    "            CFG.color)\n",
    "\n",
    "    bad_cols = None\n",
    "    cat_cols = None\n",
    "    lgb_models = None\n",
    "    ctb_models = None\n",
    "    lgb_models_oof = None\n",
    "    ctb_models_oof = None\n",
    "\n",
    "    def train_model():            \n",
    "        train, model_2.bad_cols, model_2.cat_cols = model_2.fe.apply_fe(model_2.CFG.train_path)\n",
    "        train = train.to_pandas()\n",
    "        if APP.short_dataset:\n",
    "            train = train[:1000]\n",
    "        model_2.lgb_models, lgb_oof_preds = model_2.md.train_model(train, model_2.cat_cols, title='LightGBM')\n",
    "        model_2.ctb_models, ctb_oof_preds = model_2.md.train_model(train, model_2.cat_cols, title='CatBoost')\n",
    "        train['lgb_oof_preds'] = lgb_oof_preds\n",
    "        train['ctb_oof_preds'] = ctb_oof_preds\n",
    "        model_2.lgb_models_oof, _ = model_2.md.train_model(train, model_2.cat_cols, title='LightGBM w/ OOF')\n",
    "        model_2.ctb_models_oof, _ = model_2.md.train_model(train, model_2.cat_cols, title='CatBoost w/ OOF')\n",
    "\n",
    "    counter = 0\n",
    "    def predict(test, submission):\n",
    "        if model_2.counter == 0:\n",
    "            model_2.train_model() \n",
    "        model_2.counter += 1\n",
    "        test, _ = model_2.fe.drop_cols(test, model_2.bad_cols)\n",
    "        test = model_2.fe.cast_datatypes(test)\n",
    "        test = test.to_pandas()\n",
    "        return model_2.md.inference(test, model_2.cat_cols, model_2.lgb_models, model_2.ctb_models, model_2.lgb_models_oof, model_2.ctb_models_oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T00:38:52.405101Z",
     "iopub.status.busy": "2024-11-29T00:38:52.404539Z",
     "iopub.status.idle": "2024-11-29T00:38:52.434893Z",
     "shell.execute_reply": "2024-11-29T00:38:52.434031Z",
     "shell.execute_reply.started": "2024-11-29T00:38:52.405062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class model_3:\n",
    "    class Config:\n",
    "        train_path = '/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv'\n",
    "        early_stop = 55\n",
    "        n_splits = 5\n",
    "        seed = 1212\n",
    "        split_agent_features = True\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        mlp_params = {\n",
    "            'input_dim': None,\n",
    "            'hidden_dims': [\n",
    "                512, 512, 512, 512,\n",
    "                256, 256, 256, 256,\n",
    "                128, 128, 128, 128,\n",
    "                64, 64, 64, 64,\n",
    "                32, 32, 32, 32\n",
    "            ],\n",
    "            'dropout_rate': 0.35,\n",
    "            'learning_rate': 0.0008,\n",
    "            'batch_size': 256,\n",
    "            'epochs': 200,\n",
    "            'use_residual': True,\n",
    "        }\n",
    "\n",
    "    class DataProcessor:\n",
    "        def __init__(self, dropped_cols, agent_cols):\n",
    "            self.dropped_cols = dropped_cols\n",
    "            self.agent_cols = agent_cols\n",
    "            self.scaler = StandardScaler()\n",
    "            self.label_encoders = {}  \n",
    "\n",
    "        def process_data(self, df):\n",
    "            df = df.drop(filter(lambda x: x in df.columns, self.dropped_cols))\n",
    "        \n",
    "        \n",
    "            if Config.split_agent_features:\n",
    "                for col in self.agent_cols:\n",
    "                    df = df.with_columns(\n",
    "                        pl.col(col).str.split(by=\"-\").list.to_struct(fields=lambda idx: f\"{col}_{idx}\")\n",
    "                    ).unnest(col).drop(f\"{col}_0\")\n",
    "        \n",
    "     \n",
    "            df = df.to_pandas()\n",
    "        \n",
    "        \n",
    "            categorical_cols = [col for col in df.columns if col[:6] in self.agent_cols]\n",
    "            numerical_cols = [col for col in df.columns if col[:6] not in self.agent_cols]\n",
    "        \n",
    "        \n",
    "            for col in categorical_cols:\n",
    "                if col not in self.label_encoders:\n",
    "                    self.label_encoders[col] = LabelEncoder()\n",
    "                    df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "                else:\n",
    "                    try:\n",
    "                        df[col] = self.label_encoders[col].transform(df[col])\n",
    "                    except ValueError:  \n",
    "                        new_categories = set(df[col]) - set(self.label_encoders[col].classes_)\n",
    "                        old_classes = self.label_encoders[col].classes_\n",
    "                        n_old_classes = len(old_classes)\n",
    "                        new_values = {cat: i + n_old_classes for i, cat in enumerate(new_categories)}\n",
    "                        df[col] = df[col].map(lambda x: new_values.get(x, self.label_encoders[col].transform([x])[0]))\n",
    "        \n",
    "        \n",
    "            df[numerical_cols] = df[numerical_cols].astype(np.float32)\n",
    "        \n",
    "            print(f'Data shape after processing agents: {df.shape}')\n",
    "            return df\n",
    "\n",
    "        def feature_engineering(self, df):\n",
    "        \n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "            df_numeric = df[numeric_cols].copy()\n",
    "        \n",
    "            df_numeric['Playouts/Moves'] = df_numeric['PlayoutsPerSecond'] / (df_numeric['MovesPerSecond'] + 1e-15)\n",
    "            df_numeric['EfficiencyPerPlayout'] = df_numeric['MovesPerSecond'] / (df_numeric['PlayoutsPerSecond'] + 1e-15)\n",
    "            df_numeric['TurnsDurationEfficiency'] = df_numeric['DurationActions'] / (df_numeric['DurationTurnsStdDev'] + 1e-15)\n",
    "            df_numeric['AdvantageBalanceRatio'] = df_numeric['AdvantageP1'] / (df_numeric['Balance'] + 1e-15)\n",
    "            df_numeric['ActionTimeEfficiency'] = df_numeric['DurationActions'] / (df_numeric['MovesPerSecond'] + 1e-15)\n",
    "            df_numeric['StandardizedTurnsEfficiency'] = df_numeric['DurationTurnsStdDev'] / (df_numeric['DurationActions'] + 1e-15)\n",
    "            df_numeric['AdvantageTimeImpact'] = df_numeric['AdvantageP1'] / (df_numeric['DurationActions'] + 1e-15)\n",
    "            df_numeric['DurationToComplexityRatio'] = df_numeric['DurationActions'] / (df_numeric['StateTreeComplexity'] + 1e-15)\n",
    "            df_numeric['NormalizedGameTreeComplexity'] = df_numeric['GameTreeComplexity'] / (df_numeric['StateTreeComplexity'] + 1e-15)\n",
    "            df_numeric['ComplexityBalanceInteraction'] = df_numeric['Balance'] * df_numeric['GameTreeComplexity']\n",
    "            df_numeric['OverallComplexity'] = df_numeric['StateTreeComplexity'] + df_numeric['GameTreeComplexity']\n",
    "            df_numeric['ComplexityPerPlayout'] = df_numeric['GameTreeComplexity'] / (df_numeric['PlayoutsPerSecond'] + 1e-15)\n",
    "            df_numeric['TurnsNotTimeouts/Moves'] = df_numeric['DurationTurnsNotTimeouts'] / (df_numeric['MovesPerSecond'] + 1e-15)\n",
    "            df_numeric['Timeouts/DurationActions'] = df_numeric['Timeouts'] / (df_numeric['DurationActions'] + 1e-15)\n",
    "            df_numeric['OutcomeUniformity/AdvantageP1'] = df_numeric['OutcomeUniformity'] / (df_numeric['AdvantageP1'] + 1e-15)\n",
    "            df_numeric['ComplexDecisionRatio'] = (df_numeric['StepDecisionToEnemy'] + \n",
    "                                            df_numeric['SlideDecisionToEnemy'] + \n",
    "                                            df_numeric['HopDecisionMoreThanOne'])\n",
    "            df_numeric['AggressiveActionsRatio'] = (df_numeric['StepDecisionToEnemy'] + \n",
    "                                               df_numeric['HopDecisionEnemyToEnemy'] + \n",
    "                                               df_numeric['HopDecisionFriendToEnemy'] + \n",
    "                                               df_numeric['SlideDecisionToEnemy'])\n",
    "\n",
    "            new_features = [\n",
    "            'Playouts/Moves', 'EfficiencyPerPlayout', 'TurnsDurationEfficiency',\n",
    "            'AdvantageBalanceRatio', 'ActionTimeEfficiency', 'StandardizedTurnsEfficiency',\n",
    "            'AdvantageTimeImpact', 'DurationToComplexityRatio', 'NormalizedGameTreeComplexity',\n",
    "            'ComplexityBalanceInteraction', 'OverallComplexity', 'ComplexityPerPlayout',\n",
    "            'TurnsNotTimeouts/Moves', 'Timeouts/DurationActions', 'OutcomeUniformity/AdvantageP1',\n",
    "            'ComplexDecisionRatio', 'AggressiveActionsRatio'\n",
    "            ]\n",
    "\n",
    "       \n",
    "            for col in new_features:\n",
    "                df[col] = df_numeric[col]\n",
    "\n",
    "            print(f'Data shape after new_features: {df.shape}')\n",
    "            return df, new_features\n",
    "\n",
    "        def process_and_engineer(self, df):\n",
    "            df = self.process_data(df)\n",
    "            df, new_features = self.feature_engineering(df)\n",
    "            return df, new_features\n",
    "\n",
    "    class MCTSDataset(Dataset):\n",
    "        def __init__(self, X, y=None):\n",
    "            self.X = torch.FloatTensor(X)\n",
    "            self.y = torch.FloatTensor(y) if y is not None else None\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            if self.y is not None:\n",
    "                return self.X[idx], self.y[idx]\n",
    "            return self.X[idx]\n",
    "\n",
    "    class MLPModel(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dims, dropout_rate=0.3, use_residual=True):\n",
    "            super().__init__()\n",
    "            layers = []\n",
    "            prev_dim = input_dim\n",
    "\n",
    "            for hidden_dim in hidden_dims:\n",
    "                layers.append(nn.Sequential(\n",
    "                    nn.Linear(prev_dim, hidden_dim),\n",
    "                    nn.BatchNorm1d(hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(dropout_rate)\n",
    "                ))\n",
    "                prev_dim = hidden_dim\n",
    "\n",
    "            layers.append(nn.Linear(prev_dim, 1))\n",
    "            self.model = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.model(x).squeeze()\n",
    "\n",
    "    def __init__(self, dropped_cols, agent_cols):\n",
    "        self.processor = self.DataProcessor(dropped_cols, agent_cols)\n",
    "        self.models = []\n",
    "        self.scalers = []\n",
    "\n",
    "    def train_model(self, train_df, group_col):\n",
    "        X = train_df.drop(['utility_agent1'], axis=1)\n",
    "        y = train_df['utility_agent1']\n",
    "\n",
    "        self.Config.mlp_params['input_dim'] = X.shape[1]\n",
    "        group_kfold = GroupKFold(n_splits=self.Config.n_splits)\n",
    "\n",
    "        for fi, (train_idx, valid_idx) in enumerate(group_kfold.split(X, y, groups=group_col)):\n",
    "            print(f'Fold {fi + 1}/{self.Config.n_splits} ...')\n",
    "\n",
    "            X_train, X_valid = X.iloc[train_idx].values, X.iloc[valid_idx].values\n",
    "            y_train, y_valid = y.iloc[train_idx].values, y.iloc[valid_idx].values\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_valid = scaler.transform(X_valid)\n",
    "\n",
    "            train_dataset = self.MCTSDataset(X_train, y_train)\n",
    "            valid_dataset = self.MCTSDataset(X_valid, y_valid)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.Config.mlp_params['batch_size'], shuffle=True)\n",
    "            valid_loader = DataLoader(valid_dataset, batch_size=self.Config.mlp_params['batch_size'])\n",
    "\n",
    "            model = self.MLPModel(\n",
    "                self.Config.mlp_params['input_dim'],\n",
    "                self.Config.mlp_params['hidden_dims'],\n",
    "                self.Config.mlp_params['dropout_rate']\n",
    "            ).to(self.Config.device)\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=self.Config.mlp_params['learning_rate'])\n",
    "\n",
    "            best_valid_rmse = float('inf')\n",
    "            for epoch in range(self.Config.mlp_params['epochs']):\n",
    "                model.train()\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(self.Config.device), batch_y.to(self.Config.device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                valid_preds = []\n",
    "                valid_targets = []\n",
    "                with torch.no_grad():\n",
    "                    for batch_X, batch_y in valid_loader:\n",
    "                        batch_X = batch_X.to(self.Config.device)\n",
    "                        outputs = model(batch_X)\n",
    "                        valid_preds.extend(outputs.cpu().numpy())\n",
    "                        valid_targets.extend(batch_y.numpy())\n",
    "\n",
    "                valid_rmse = mean_squared_error(valid_targets, valid_preds, squared=False)\n",
    "                if valid_rmse < best_valid_rmse:\n",
    "                    best_valid_rmse = valid_rmse\n",
    "\n",
    "            self.models.append(model)\n",
    "            self.scalers.append(scaler)\n",
    "\n",
    "    def infer_model(self, test_df):\n",
    "        predictions = []\n",
    "        for model, scaler in zip(self.models, self.scalers):\n",
    "            X = scaler.transform(test_df.values)\n",
    "            X_tensor = torch.FloatTensor(X).to(self.Config.device)\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                predictions.append(model(X_tensor).cpu().numpy())\n",
    "\n",
    "        return np.mean(predictions, axis=0)\n",
    "\n",
    "    def predict(self, test, submission):\n",
    "        processed_test_df = self.processor.process_and_engineer(test)\n",
    "        predictions = self.infer_model(processed_test_df)\n",
    "        # return submission.with_columns(\n",
    "        #     pl.Series('utility_agent1', predictions)\n",
    "        # )\n",
    "        return predictions\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# **》》》Filanly. Blend & Call Inference**\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T00:38:52.436187Z",
     "iopub.status.busy": "2024-11-29T00:38:52.435931Z",
     "iopub.status.idle": "2024-11-29T00:38:52.448472Z",
     "shell.execute_reply": "2024-11-29T00:38:52.447848Z",
     "shell.execute_reply.started": "2024-11-29T00:38:52.436165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def predict(test, submission):\n",
    "#      result_1 = model_1.predict(test, submission)\n",
    "#      result_2 = model_2.predict(test, submission)\n",
    "#      return submission.with_columns(pl.Series('utility_agent1', result_1*0.50 + result_2*0.50))\n",
    "\n",
    "# if APP.local and not APP.submit:\n",
    "#      test = pl.read_csv(APP.test_file)\n",
    "#      submission = pl.read_csv(APP.sample_subm_file)\n",
    "#      result = predict(test, submission)\n",
    "# else:\n",
    "#      # Call the gateway server\n",
    "#      inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "#      if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "#          inference_server.serve()\n",
    "#      else:\n",
    "#          inference_server.run_local_gateway((APP.test_file, APP.sample_subm_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T00:38:52.450148Z",
     "iopub.status.busy": "2024-11-29T00:38:52.449923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(test, submission):\n",
    "    result_1 = model_1.predict(test, submission)\n",
    "    result_2 = model_2.predict(test, submission)\n",
    "    # result_3 = model_3.predict(test, submission)\n",
    "    final_prediction = (result_1 * 0.5 + result_2 * 0.5)\n",
    "    return submission.with_columns(pl.Series('utility_agent1', final_prediction))\n",
    "\n",
    "if APP.local and not APP.submit:\n",
    "    test = pl.read_csv(APP.test_file)\n",
    "    submission = pl.read_csv(APP.sample_subm_file)\n",
    "    result = predict(test, submission)\n",
    "else:\n",
    "    # Call the gateway server\n",
    "    inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "    if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway((APP.test_file, APP.sample_subm_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9515283,
     "sourceId": 70089,
     "sourceType": "competition"
    },
    {
     "sourceId": 197802518,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 205389271,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14712.68966,
   "end_time": "2024-09-22T23:16:49.083675",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-22T19:11:36.394015",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
